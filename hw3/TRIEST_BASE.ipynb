{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Homework 3: Mining Data Streams\n",
    "You are to study and implement a streaming graph processing algorithm described in one of the above papers of your choice.   \n",
    "In order to accomplished your task, you are to perform the following two steps  \n",
    "\n",
    "First, implement the reservoir sampling or the Flajolet-Martin algorithm used in the graph algorithm presented in the paper you have selected;  \n",
    "Second, implement the streaming graph algorithm presented in the paper that make use of the algorithm implemented in the first step.   \n",
    "#### Group 28\n",
    "Junjie Shan & Yuxin Meng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Algorithm\n",
    "we chose to implement the second paper(both base and impr versions):  \n",
    "L. De Stefani, A. Epasto, M. Riondato, and E. Upfal, **TRIÃˆST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size**, KDD'16.  \n",
    "link: http://www.kdd.org/kdd2016/papers/files/rfp0465-de-stefaniA.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented two algorithms TRIST_BASE and TRIST_IMPR, which can only deal with insertion-only streams, to estimate the global and local triangles of an ongoing stream of graph (with only insertions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TRIEST_BASE:\n",
    "    def __init__(self, M = 100):\n",
    "        self.M = M\n",
    "        self.S = set()\n",
    "        self.global_counter = 0\n",
    "        self.local_counter = {}\n",
    "        self.t = 0\n",
    "\n",
    "    # Using the reservoir sampling process, and each edge item in the sample has equal probability.\n",
    "    def sample_edge(self, Edge, t):\n",
    "        # when t <= M, the edge is deterministically inserted in S\n",
    "        if t <= self.M:\n",
    "            return True\n",
    "        # with probability M/t to be true, it will choose an existing edge in S uniformly at random\n",
    "        if random.random() <= (self.M/t):\n",
    "            random_edge = random.sample(self.S, 1)[0]\n",
    "            # remove it and insert the current edge on time t into S \n",
    "            self.S.remove(random_edge)\n",
    "            self.update_counters('-', Edge)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def update_counters(self, operation, edge):\n",
    "        # edge E = (u,v)\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "        neighborhood_of_u = set()\n",
    "        neighborhood_of_v = set()\n",
    "        # construct neighborhood of u\n",
    "        for one_edge in self.S:\n",
    "            if u == one_edge[0]:\n",
    "                neighborhood_of_u.add(one_edge[1])\n",
    "            if u == one_edge[1]:\n",
    "                neighborhood_of_u.add(one_edge[0])\n",
    "            # construct neighborhood of v\n",
    "            if v == one_edge[0]:\n",
    "                neighborhood_of_v.add(one_edge[1])\n",
    "            if v == one_edge[1]:\n",
    "                neighborhood_of_v.add(one_edge[0])\n",
    "        # shared neighborhood of u and v\n",
    "        shared_neighborhood = set.intersection(neighborhood_of_u, neighborhood_of_v)\n",
    "        # update counters\n",
    "        for c in shared_neighborhood:\n",
    "            if operation == '+':\n",
    "                self.global_counter += 1\n",
    "                self.local_counter[c] = self.local_counter.get(c, 0) + 1\n",
    "                self.local_counter[u] = self.local_counter.get(u, 0) + 1\n",
    "                self.local_counter[v] = self.local_counter.get(v, 0) + 1\n",
    "\n",
    "            if operation == '-':\n",
    "                self.global_counter -= 1\n",
    "                self.local_counter[c] = self.local_counter.get(c, 0) - 1\n",
    "                if self.local_counter[c] <= 0:\n",
    "                    del self.local_counter[c]\n",
    "                self.local_counter[u] = self.local_counter.get(u, 0) - 1\n",
    "                if self.local_counter[u] <= 0:\n",
    "                    del self.local_counter[u]\n",
    "                self.local_counter[v] = self.local_counter.get(v, 0) - 1\n",
    "                if self.local_counter[v] <= 0:\n",
    "                    del self.local_counter[v]\n",
    "\n",
    "    def run_triest_base(self, streams):\n",
    "\n",
    "        for element in streams:\n",
    "            self.t += 1\n",
    "            if self.sample_edge(element, self.t):\n",
    "                self.S.add(element)\n",
    "                self.update_counters('+', element)\n",
    "\n",
    "        eps = (self.t * (self.t - 1) * (self.t - 2)) / (self.M * (self.M - 1) * (self.M - 2))\n",
    "\n",
    "        eps = max(1, eps)\n",
    "        print('Epsilon is ', eps)\n",
    "        # estimation for the global triangle count\n",
    "        est_gc = eps * self.global_counter\n",
    "        return est_gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data pre-processing\n",
    "The dataset we used is the High Energy Physics - Theory collaboration network. (https://snap.stanford.edu/data/ca-HepTh.html)    \n",
    "|dataset statistics||\n",
    "|  ----  | ----  |\n",
    "Nodes|\t9877\n",
    "Edges|\t25998\n",
    "Nodes in largest WCC|\t8638 (0.875)\n",
    "Edges in largest WCC|\t24827 (0.955)\n",
    "Nodes in largest SCC|\t8638 (0.875)\n",
    "Edges in largest SCC|\t24827 (0.955)\n",
    "Average clustering coefficient|\t0.4714\n",
    "Number of triangles|\t28339\n",
    "Fraction of closed triangles|\t0.1168\n",
    "Diameter (longest shortest path)|\t17\n",
    "90-percentile effective diameter|\t7.4\n",
    "\n",
    "Although the dataset's information shows that it contains undirected edges, however, in actual file, there are more than 25998 edges.  \n",
    "So we need to pre-process the dataset, to make the edge, for example, Edge(562, 9890) be the same as Edge(9890, 562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of edges of Data Stream contains 25973\n"
     ]
    }
   ],
   "source": [
    "def undirected_edge(u,v):\n",
    "    if u < v:\n",
    "        return (u,v)\n",
    "    else:\n",
    "        return (v,u)\n",
    "\n",
    "# import dataset\n",
    "streams = set()\n",
    "\n",
    "with open(\"CA-HepTh.txt\") as f:\n",
    "    for line in f:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        edge = line.split()\n",
    "        if edge[0] != edge[1]:\n",
    "            streams.add(undirected_edge(edge[0], edge[1]))\n",
    "        # if size_stream == 10000:\n",
    "        #     break\n",
    "\n",
    "print('The amount of edges of Data Stream contains', len(streams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of M is 3000\n",
      "Epsilon is  649.5114821120048\n",
      "Estimation for the global triangle count is 28578.505212928212\n",
      "the value of M is 25973\n",
      "Epsilon is  1\n",
      "Actual global triangle count is 28339\n",
      "Error triangles are 239.50521292821213\n",
      "Error rate is 0.008451434875197153\n"
     ]
    }
   ],
   "source": [
    "# set M >=6 & M < length of the dataset\n",
    "# Estimate the global triangle count\n",
    "triest_base = TRIEST_BASE(3000)\n",
    "print('the value of M is', triest_base.M)\n",
    "glo_tri_counter = triest_base.run_triest_base(streams)\n",
    "print('Estimation for the global triangle count is', glo_tri_counter)\n",
    "\n",
    "# Get the true amount of global triangles\n",
    "triest_base = TRIEST_BASE(len(streams))\n",
    "print('the value of M is', len(streams))\n",
    "true_glo_tri_counter = triest_base.run_triest_base(streams)\n",
    "print('Actual global triangle count is', true_glo_tri_counter)\n",
    "\n",
    "# Compare the estimation & Actual count\n",
    "error_count = abs(true_glo_tri_counter - glo_tri_counter)\n",
    "print('Error triangles are', error_count)\n",
    "error_rate = error_count/ true_glo_tri_counter\n",
    "print('Error rate is', error_rate)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
